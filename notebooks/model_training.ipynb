{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping rows with missing values...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with missing values dropped.\n",
      "Converting date columns to datetime...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 104.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date columns converted to datetime.\n",
      "Encoding categorical variables...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 157.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical variables encoded.\n",
      "hotel_name encoding:\n",
      "Original values: {0: 'Algarve Retreat', 1: 'Braga City Hotel', 2: 'Duro Valley Resort', 3: 'Lisbon City Hotel', 4: 'Porto City Hotel'}\n",
      "meal encoding:\n",
      "Original values: {0: 'BB', 1: 'HB', 2: 'SC', 3: 'Undefined', 4: 'FB'}\n",
      "source_country encoding:\n",
      "Original values: {0: 'PRT', 1: 'FRA', 2: 'JPN', 3: 'DEU', 4: 'GBR', 5: 'ESP', 6: 'POL', 7: 'BRA', 8: 'AUT', 9: 'FIN', 10: 'NLD', 11: 'CPV', 12: 'ITA', 13: 'CHN', 14: 'GRC', 15: 'ARG', 16: 'IRL', 17: 'RUS', 18: 'CHE', 19: 'BEL', 20: 'USA', 21: 'THA', 22: 'LTU', 23: 'TWN', 24: 'BHR', 25: 'CN', 26: 'SAU', 27: 'AGO', 28: 'NOR', 29: 'LUX', 30: 'EST', 31: 'ROU', 32: 'SWE', 33: 'MKD', 34: 'ISR', 35: 'ZAF', 36: 'COL', 37: 'MEX', 38: 'OMN', 39: 'GIB', 40: 'MNE', 41: 'AND', 42: 'AUS', 43: 'DNK', 44: 'IRN', 45: 'CZE', 46: 'KOR', 47: 'KEN', 48: 'MYS', 49: 'SVN', 50: 'SMR', 51: 'UKR', 52: 'BGR', 53: 'SRB', 54: 'TUN', 55: 'TUR', 56: 'LVA', 57: 'HRV', 58: 'HUN', 59: 'IDN', 60: 'DZA', 61: 'BLR', 62: 'ATA', 63: 'PRI', 64: 'CMR', 65: 'URY', 66: 'CRI', 67: 'LBN', 68: 'VEN', 69: 'MAR', 70: 'SUR', 71: 'SGP', 72: 'JAM', 73: 'CUB', 74: 'PLW', 75: 'MOZ', 76: 'UGA', 77: 'PER', 78: 'ALB', 79: 'IND', 80: 'HKG', 81: 'NZL', 82: 'MLT', 83: 'BRB', 84: 'KWT', 85: 'GEO', 86: 'CHL', 87: 'VNM', 88: 'QAT', 89: 'EGY', 90: 'ARE', 91: 'SVK', 92: 'KAZ', 93: 'PHL', 94: 'ISL', 95: 'AZE', 96: 'PAK', 97: 'PAN', 98: 'IRQ', 99: 'SLV', 100: 'MDV', 101: 'CYP', 102: 'BGD', 103: 'LAO', 104: 'NGA', 105: 'NPL', 106: 'LKA', 107: 'DOM', 108: 'GLP', 109: 'ARM', 110: 'CIV', 111: 'COM', 112: 'JEY', 113: 'UMI', 114: 'BHS', 115: 'ZWE', 116: 'ECU', 117: 'CAF', 118: 'MAC', 119: 'SYC', 120: 'MUS', 121: 'BOL', 122: 'SEN', 123: 'MWI', 124: 'JOR', 125: 'LBY', 126: 'ZMB', 127: 'FJI', 128: 'GNB', 129: 'KNA', 130: 'RWA', 131: 'BIH', 132: 'TZA', 133: 'TJK', 134: 'LIE', 135: 'FRO', 136: 'ETH', 137: 'STP', 138: 'GAB', 139: 'TMP', 140: 'SYR', 141: 'KIR', 142: 'UZB', 143: 'SDN', 144: 'AIA', 145: 'ATF', 146: 'MCO', 147: 'BEN', 148: 'NCL', 149: 'DJI', 150: 'PRY', 151: 'BDI', 152: 'MDG', 153: 'GTM', 154: 'GGY', 155: 'GUY', 156: 'BFA', 157: 'NAM', 158: 'MLI', 159: 'VGB', 160: 'NIC', 161: 'TGO', 162: 'IMN', 163: 'ABW', 164: 'MRT', 165: 'MYT', 166: 'DMA', 167: 'KHM', 168: 'GHA', 169: 'SLE'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "market_segment encoding:\n",
      "Original values: {0: 'Online TA', 1: 'Groups', 2: 'Direct', 3: 'Corporate', 4: 'Offline TA/TO', 5: 'Complementary', 6: 'Aviation', 7: 'Undefined'}\n",
      "distribution_channel encoding:\n",
      "Original values: {0: 'Direct', 1: 'TA/TO', 2: 'Corporate', 3: 'GDS', 4: 'Undefined'}\n",
      "assigned_room_type encoding:\n",
      "Original values: {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'K', 10: 'L'}\n",
      "guest_type encoding:\n",
      "Original values: {0: 'Group', 1: 'Family', 2: 'Couple', 3: 'Single'}\n",
      "customer_type encoding:\n",
      "Original values: {0: 'Transient-Party', 1: 'Transient', 2: 'Group', 3: 'Contract'}\n",
      "season encoding:\n",
      "Original values: {0: 'Spring', 1: 'Summer', 2: 'Autumn', 3: 'Winter'}\n",
      "company encoding:\n",
      "Original values: {0: 40.0, 1: 130.0, 2: 174.0, 3: 154.0, 4: 186.0, 5: 223.0, 6: 102.0, 7: 67.0, 8: 153.0, 9: 351.0, 10: 62.0, 11: 233.0, 12: 110.0, 13: 448.0, 14: 291.0, 15: 94.0, 16: 45.0, 17: 219.0, 18: 51.0, 19: 268.0, 20: 270.0, 21: 38.0, 22: 39.0, 23: 240.0, 24: 20.0, 25: 346.0, 26: 290.0, 27: 371.0, 28: 68.0, 29: 355.0, 30: 281.0, 31: 197.0, 32: 365.0, 33: 331.0, 34: 46.0, 35: 135.0, 36: 307.0, 37: 343.0, 38: 47.0, 39: 83.0, 40: 31.0, 41: 405.0, 42: 179.0, 43: 366.0, 44: 450.0, 45: 218.0, 46: 269.0, 47: 459.0, 48: 195.0, 49: 274.0, 50: 144.0, 51: 127.0, 52: 113.0, 53: 286.0, 54: 324.0, 55: 348.0, 56: 92.0, 57: 329.0, 58: 118.0, 59: 43.0, 60: 342.0, 61: 88.0, 62: 238.0, 63: 485.0, 64: 337.0, 65: 81.0, 66: 99.0, 67: 148.0, 68: 12.0, 69: 451.0, 70: 361.0, 71: 91.0, 72: 108.0, 73: 338.0, 74: 216.0, 75: 204.0, 76: 364.0, 77: 400.0, 78: 367.0, 79: 443.0, 80: 395.0, 81: 227.0, 82: 382.0, 83: 399.0, 84: 105.0, 85: 515.0, 86: 275.0, 87: 301.0, 88: 82.0, 89: 494.0, 90: 167.0, 91: 379.0, 92: 53.0, 93: 165.0, 94: 169.0, 95: 178.0, 96: 357.0, 97: 384.0, 98: 392.0, 99: 401.0, 100: 282.0, 101: 435.0, 102: 292.0, 103: 86.0, 104: 34.0, 105: 409.0, 106: 232.0, 107: 498.0, 108: 413.0, 109: 308.0, 110: 416.0, 111: 18.0, 112: 193.0, 113: 523.0, 114: 54.0, 115: 396.0, 116: 9.0, 117: 407.0, 118: 234.0, 119: 323.0, 120: 72.0, 121: 42.0, 122: 445.0, 123: 78.0, 124: 444.0, 125: 426.0, 126: 394.0, 127: 143.0, 128: 317.0, 129: 457.0, 130: 380.0, 131: 200.0, 132: 334.0, 133: 460.0, 134: 28.0, 135: 466.0, 136: 215.0, 137: 403.0, 138: 477.0, 139: 263.0, 140: 37.0, 141: 388.0, 142: 421.0, 143: 341.0, 144: 59.0, 145: 103.0, 146: 470.0, 147: 504.0, 148: 272.0, 149: 207.0, 150: 224.0, 151: 507.0, 152: 159.0, 153: 514.0, 154: 242.0, 155: 356.0, 156: 146.0, 157: 353.0, 158: 22.0, 159: 225.0, 160: 255.0, 161: 254.0, 162: 385.0, 163: 48.0, 164: 116.0, 165: 163.0, 166: 521.0, 167: 525.0, 168: 112.0, 169: 52.0, 170: 452.0, 171: 137.0, 172: 221.0, 173: 539.0, 174: 520.0, 175: 202.0, 176: 397.0, 177: 150.0, 178: 330.0, 179: 158.0, 180: 419.0, 181: 120.0, 182: 428.0, 183: 390.0, 184: 325.0, 185: 378.0, 186: 360.0, 187: 122.0, 188: 183.0, 189: 280.0, 190: 424.0, 191: 347.0, 192: 349.0, 193: 192.0, 194: 250.0, 195: 373.0, 196: 511.0, 197: 14.0, 198: 297.0, 199: 313.0, 200: 277.0, 201: 402.0, 202: 302.0, 203: 16.0, 204: 465.0, 205: 415.0, 206: 184.0, 207: 32.0, 208: 486.0, 209: 491.0, 210: 499.0, 211: 513.0, 212: 251.0, 213: 528.0, 214: 84.0, 215: 220.0, 216: 391.0, 217: 271.0, 218: 212.0, 219: 287.0, 220: 436.0, 221: 333.0, 222: 447.0, 223: 418.0, 224: 458.0, 225: 437.0, 226: 393.0, 227: 246.0, 228: 516.0, 229: 93.0, 230: 260.0, 231: 446.0, 232: 423.0, 233: 115.0, 234: 185.0, 235: 107.0, 236: 203.0, 237: 209.0, 238: 35.0, 239: 245.0, 240: 213.0, 241: 71.0, 242: 253.0, 243: 312.0, 244: 311.0, 245: 377.0, 246: 332.0, 247: 408.0, 248: 410.0, 249: 412.0, 250: 439.0, 251: 478.0, 252: 479.0, 253: 489.0, 254: 497.0, 255: 492.0, 256: 372.0, 257: 501.0, 258: 358.0, 259: 305.0, 260: 320.0, 261: 433.0, 262: 383.0, 263: 496.0, 264: 101.0, 265: 398.0, 266: 210.0, 267: 352.0, 268: 278.0, 269: 369.0, 270: 264.0, 271: 139.0, 272: 487.0, 273: 77.0, 274: 319.0, 275: 168.0, 276: 29.0, 277: 506.0, 278: 512.0, 279: 64.0, 280: 518.0, 281: 530.0, 282: 541.0, 283: 80.0, 284: 257.0, 285: 109.0, 286: 289.0, 287: 482.0, 288: 490.0, 289: 6.0, 290: 376.0, 291: 425.0, 292: 318.0, 293: 370.0, 294: 454.0, 295: 442.0, 296: 316.0, 297: 49.0, 298: 140.0, 299: 8.0, 300: 149.0, 301: 85.0, 302: 222.0, 303: 259.0, 304: 293.0, 305: 309.0, 306: 350.0, 307: 362.0, 308: 180.0, 309: 73.0, 310: 429.0, 311: 76.0, 312: 160.0, 313: 65.0, 314: 96.0, 315: 100.0, 316: 534.0, 317: 304.0, 318: 321.0, 319: 217.0, 320: 368.0, 321: 142.0, 322: 230.0, 323: 106.0, 324: 237.0, 325: 229.0, 326: 417.0, 327: 483.0, 328: 11.0, 329: 284.0, 330: 411.0}\n",
      "Dropping duplicate rows...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 rows dropped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "data_folder = os.path.join('..','data')\n",
    "file_to_open = os.path.join(data_folder,\"hotel_bookings.csv\")\n",
    "sys.path.append(os.path.join('..','src'))\n",
    "from utils import DataLoader\n",
    "from data_preprocessing import DataPreprocessor\n",
    "from feature_engineering import HotelBookingFeatures\n",
    "\n",
    "data_loader = DataLoader()\n",
    "hotel_bookings = data_loader.load_data(file_to_open)\n",
    "\n",
    "# create an instance of the HotelBookingFeatures class\n",
    "booking_features = HotelBookingFeatures(hotel_bookings)\n",
    "\n",
    "# add the new columns to the DataFrame\n",
    "booking_features.is_weekend_stay()\n",
    "booking_features.num_days_stayed()\n",
    "booking_features.booking_lead_time()\n",
    "\n",
    "# create an instance of the DataPreprocessor class\n",
    "data_preprocessor = DataPreprocessor(hotel_bookings)\n",
    "\n",
    "# preprocess the data using the various methods\n",
    "data_preprocessor.drop_na_columns()\n",
    "data_preprocessor.convert_datetime()\n",
    "data_preprocessor.encode_categorical_variables()\n",
    "data_preprocessor.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 60.72233154989432\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# calculate the mean value of stay_days\n",
    "mean_stay_days = hotel_bookings['num_days_stayed'].mean()\n",
    "\n",
    "# create a list of predictions with the same length as the number of instances\n",
    "predictions = [mean_stay_days] * len(hotel_bookings)\n",
    "\n",
    "# calculate the mean squared error of the predictions\n",
    "mse = mean_squared_error(hotel_bookings['num_days_stayed'], predictions)\n",
    "\n",
    "# print the mean squared error\n",
    "print('Mean Squared Error:', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AnasSuffo/Library/Caches/pypoetry/virtualenvs/tui-cruises-challenge-AZyxbE26-py3.11/lib/python3.11/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for seasonal ARMA. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.67942D-01    |proj g|=  3.93286D-02\n",
      "\n",
      "At iterate    5    f=  8.61337D-01    |proj g|=  1.22496D-02\n",
      "\n",
      "At iterate   10    f=  8.55363D-01    |proj g|=  2.75375D-03\n",
      "\n",
      "At iterate   15    f=  8.55264D-01    |proj g|=  1.42057D-04\n",
      "\n",
      "At iterate   20    f=  8.55259D-01    |proj g|=  1.73905D-03\n",
      "\n",
      "At iterate   25    f=  8.55229D-01    |proj g|=  1.02611D-03\n",
      "\n",
      "At iterate   30    f=  8.55210D-01    |proj g|=  1.69180D-03\n",
      "\n",
      "At iterate   35    f=  8.55195D-01    |proj g|=  8.31375D-04\n",
      "\n",
      "At iterate   40    f=  8.55188D-01    |proj g|=  1.70254D-04\n",
      "\n",
      "At iterate   45    f=  8.55185D-01    |proj g|=  1.40838D-04\n",
      "\n",
      "At iterate   50    f=  8.55183D-01    |proj g|=  8.87099D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     50     61      1     0     0   8.871D-05   8.552D-01\n",
      "  F =  0.85518309191146147     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AnasSuffo/Library/Caches/pypoetry/virtualenvs/tui-cruises-challenge-AZyxbE26-py3.11/lib/python3.11/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 71.65085506123651\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# define a new dataframe with the arrival_date column as the index\n",
    "sm_df = hotel_bookings.set_index('arrival_date')\n",
    "\n",
    "# resample the data to a weekly frequency and fill missing values with the mean\n",
    "weekly_bookings = sm_df['num_days_stayed'].resample('W').mean().fillna(sm_df['num_days_stayed'].mean())\n",
    "\n",
    "# fit a SARIMA model to the data\n",
    "model = sm.tsa.statespace.SARIMAX(weekly_bookings, order=(1, 1, 1), seasonal_order=(1, 1, 1, 52))\n",
    "results = model.fit()\n",
    "\n",
    "# make predictions for the next 52 weeks\n",
    "forecast = results.forecast(steps=52)\n",
    "\n",
    "# calculate the mean squared error of the predictions\n",
    "mse = mean_squared_error(weekly_bookings[-52:], forecast)\n",
    "\n",
    "# print the mean squared error\n",
    "print('Mean Squared Error:', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# read the data into a pandas DataFrame\n",
    "hotel_bookings = pd.read_csv('your_data_file.csv')\n",
    "\n",
    "# convert the arrival_date column to a datetime object and set it as the index\n",
    "hotel_bookings['arrival_date'] = pd.to_datetime(hotel_bookings['arrival_date'])\n",
    "hotel_bookings = hotel_bookings.set_index('arrival_date')\n",
    "\n",
    "# resample the data to a weekly frequency and fill missing values with the mean\n",
    "weekly_bookings = hotel_bookings['stay_days'].resample('W').mean().fillna(hotel_bookings['stay_days'].mean())\n",
    "\n",
    "# split the data into training and testing sets\n",
    "train_size = int(len(weekly_bookings) * 0.8)\n",
    "train_data, test_data = weekly_bookings[:train_size], weekly_bookings[train_size:]\n",
    "\n",
    "# normalize the data\n",
    "train_mean, train_std = train_data.mean(), train_data.std()\n",
    "train_data = (train_data - train_mean) / train_std\n",
    "test_data = (test_data - train_mean) / train_std\n",
    "\n",
    "# create sequences of length 52 for training and testing\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_length = 52\n",
    "X_train, y_train = create_sequences(train_data, seq_length)\n",
    "X_test, y_test = create_sequences(test_data, seq_length)\n",
    "\n",
    "# create an LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(seq_length, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32)\n",
    "\n",
    "# make predictions for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# calculate the mean squared error of the predictions\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# print the mean squared error\n",
    "print('Mean Squared Error:', mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tui-cruises-challenge-jTwFKr5j-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
